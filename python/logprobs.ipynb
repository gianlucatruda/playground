{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 245 µs (started: 2023-06-16 17:56:38 +01:00)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Set sensible defaults\n",
    "sns.set()\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "# Timings\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.08 ms (started: 2023-06-16 17:56:38 +01:00)\n"
     ]
    }
   ],
   "source": [
    "def augment_phrases(phrases: list[str]) -> list[str]:\n",
    "    def _iter():\n",
    "        for p in phrases:\n",
    "            yield from (f\" {p}\", p.lower(), p.upper(), p.capitalize(), p.title())\n",
    "\n",
    "    return list(set(_iter()))\n",
    "\n",
    "def complete(messages: list[str], model, **kwargs) -> str:\n",
    "    if type(messages) == str:\n",
    "        messages = [messages]\n",
    "    messages = [{\"role\": \"user\", \"content\": m} for m in messages if isinstance(m, str)]\n",
    "    response = openai.ChatCompletion.create(model=model, messages=messages, **kwargs)\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.78 ms (started: 2023-06-16 18:27:26 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# Adapted from a snippet by https://twitter.com/goodside\n",
    "import textwrap\n",
    "import openai\n",
    "import tiktoken\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# MODEL = \"gpt-3.5-turbo\"\n",
    "MODEL = \"gpt-4\"\n",
    "\n",
    "# Phrases to suppress in the model's output:\n",
    "TARGET_PHRASES = [\n",
    "    # \"YES\", \n",
    "    # \"NO\",\n",
    "    # \"MAYBE\",\n",
    "    # \"UNSURE\",\n",
    "    # \"A\", \"B\", \"C\", \"D\", \"E\", \"None\",\n",
    "    # \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\", \".\", \",\",\n",
    "    \"Assistant\",\n",
    "    \"language\",\n",
    "    \"model\",\n",
    "    \"AI\",\n",
    "    \"artificial intelligence\",\n",
    "    \"digital\",\n",
    "    \"assistant\",\n",
    "    \"virtual\",\n",
    "    \"machine learning program\",\n",
    "    \"GPT-3\",\n",
    "    \"OpenAl\",\n",
    "    \"Open-AI\",\n",
    "    \"OpenAi\" \"machine\",\n",
    "    \"computer\",\n",
    "    \"artificial\",\n",
    "    \"intelligent\",\n",
    "    \"Open.AI\",\n",
    "    \"GPT2\",\n",
    "    \"Openai\",\n",
    "    \"ArtificialIntelligence\",\n",
    "    \"natural\",\n",
    "    \"open—source\",\n",
    "    \"machine—learning\",\n",
    "    \"NLP\",\n",
    "    \"artificially intelligent\",\n",
    "    \"Ai\",\n",
    "    \"chatbot\",\n",
    "    \"chat\",\n",
    "    \"bot\",\n",
    "    \"agent\",\n",
    "    \"software\",\n",
    "    \"conversational\",\n",
    "    \"IA\",\n",
    "    \"A.I.\",\n",
    "    \"text—based\",\n",
    "    \"Al\",\n",
    "    \"advanced\",\n",
    "    \"Artifical\",\n",
    "    \"Intellime\" \"generative pre—trained transformer\",\n",
    "    \"transformers\",\n",
    "]\n",
    "encoding = tiktoken.encoding_for_model(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrases=['computer', 'BOT', 'Digital', 'Intellimegenerative pre—trained transformer', 'AL', 'open—source', ' advanced', 'A.i.', 'Open.ai', 'MODEL', 'intellimegenerative pre—trained transformer', 'Ai', 'AI', 'MACHINE LEARNING PROGRAM', 'Open.Ai', 'A.I.', ' Intellimegenerative pre—trained transformer', ' text—based', 'openaimachine', ' natural', ' OpenAimachine', 'Open—source', 'Artificially intelligent', 'ADVANCED', 'chatbot', 'artificial intelligence', 'COMPUTER', 'openai', 'AGENT', ' ArtificialIntelligence', 'digital', 'MACHINE—LEARNING', 'SOFTWARE', 'OPENAI', 'intelligent', 'chat', 'Conversational', 'artificially intelligent', ' digital', 'ARTIFICIAL INTELLIGENCE', ' Al', 'Openaimachine', 'ARTIFICAL', 'Ia', 'VIRTUAL', 'Open-ai', 'agent', 'Open-Ai', 'gpt2', 'OPENAIMACHINE', 'GPT2', 'Artificial', ' GPT2', ' intelligent', 'OPEN—SOURCE', 'OPENAL', ' agent', 'artifical', ' computer', 'CHATBOT', 'virtual', 'Artificial Intelligence', ' software', 'Advanced', 'advanced', 'Chatbot', ' Open-AI', 'Natural', 'artificialintelligence', ' AI', ' machine—learning', 'Virtual', ' Assistant', 'NATURAL', 'Machine—learning', 'IA', 'conversational', 'ia', 'Artificial intelligence', 'Intelligent', ' chat', 'model', ' Artifical', ' Ai', 'transformers', ' OpenAl', 'software', 'Chat', 'Software', ' transformers', 'nlp', 'Intellimegenerative Pre—Trained Transformer', 'INTELLIGENT', 'ARTIFICIALLY INTELLIGENT', 'Machine—Learning', ' artificial', 'Agent', 'DIGITAL', ' A.I.', 'TRANSFORMERS', ' artificial intelligence', ' bot', 'machine learning program', 'OPEN.AI', 'CONVERSATIONAL', 'Model', 'Text—Based', ' conversational', 'open.ai', 'GPT-3', ' assistant', ' IA', 'al', 'Al', 'Assistant', 'CHAT', 'artificial', ' machine learning program', 'Computer', 'bot', 'natural', 'Gpt-3', 'Machine Learning Program', ' model', 'OPEN-AI', ' NLP', 'machine—learning', 'openal', 'Bot', 'open-ai', 'Machine learning program', ' Openai', 'ARTIFICIALINTELLIGENCE', ' chatbot', 'TEXT—BASED', 'Artifical', ' Open.AI', ' open—source', 'Openai', 'INTELLIMEGENERATIVE PRE—TRAINED TRANSFORMER', 'LANGUAGE', 'Gpt2', 'Text—based', 'text—based', 'Transformers', ' artificially intelligent', 'a.i.', 'ai', ' language', 'ASSISTANT', 'gpt-3', 'Artificialintelligence', 'language', ' virtual', ' GPT-3', 'Nlp', 'assistant', 'NLP', 'ARTIFICIAL', 'Artificially Intelligent', 'Openal', 'Open—Source', 'Language']\n",
      "tokens=[58369, 68098, 3078, 2569, 77833, 41483, 12, 13, 18957, 11789, 17, 18, 2068, 24093, 2590, 13855, 32, 38432, 547, 35, 38, 40, 44, 45, 12852, 8252, 64, 1090, 44098, 82498, 15942, 70, 72, 8777, 51785, 21579, 77, 4178, 21075, 55381, 22103, 22107, 61537, 72803, 2149, 616, 1128, 4200, 3692, 73326, 70767, 1646, 12918, 29815, 21626, 4221, 26752, 643, 11396, 2692, 2192, 2706, 5778, 5780, 95383, 21656, 86170, 9884, 21149, 43678, 5277, 44190, 1697, 8867, 46761, 3241, 44203, 1708, 6826, 6830, 16047, 1199, 689, 44211, 28852, 691, 93375, 6340, 4806, 12998, 36557, 6353, 53971, 1747, 11478, 53980, 6369, 15592, 40685, 57072, 9470, 57086, 5377, 89878, 91415, 5910, 1305, 278, 2843, 8479, 32033, 1825, 91942, 2345, 39212, 5933, 11052, 14126, 3899, 22333, 318, 31039, 6975, 6465, 1342, 835, 14660, 4419, 1863, 2891, 11084, 1357, 333, 34126, 17230, 2898, 24406, 3931, 19805, 42334, 864, 5987, 6500, 7528, 362, 78188, 877, 78191, 29555, 885, 37751, 61817, 42879, 2434, 388, 1413, 33156, 396, 78220, 398, 18328, 11164, 59294, 1953, 418, 87970, 34735, 2484, 9140, 950, 48567, 5045, 25530, 444, 452, 2505, 2506, 48633, 5075, 36822, 1495, 984, 472, 7642, 2006, 15836, 88029, 480, 8677, 34288, 5109, 7669, 63479, 3065, 16895]\n",
      "logit_bias={58369: -100, 68098: -100, 3078: -100, 2569: -100, 77833: -100, 41483: -100, 12: -100, 13: -100, 18957: -100, 11789: -100, 17: -100, 18: -100, 2068: -100, 24093: -100, 2590: -100, 13855: -100, 32: -100, 38432: -100, 547: -100, 35: -100, 38: -100, 40: -100, 44: -100, 45: -100, 12852: -100, 8252: -100, 64: -100, 1090: -100, 44098: -100, 82498: -100, 15942: -100, 70: -100, 72: -100, 8777: -100, 51785: -100, 21579: -100, 77: -100, 4178: -100, 21075: -100, 55381: -100, 22103: -100, 22107: -100, 61537: -100, 72803: -100, 2149: -100, 616: -100, 1128: -100, 4200: -100, 3692: -100, 73326: -100, 70767: -100, 1646: -100, 12918: -100, 29815: -100, 21626: -100, 4221: -100, 26752: -100, 643: -100, 11396: -100, 2692: -100, 2192: -100, 2706: -100, 5778: -100, 5780: -100, 95383: -100, 21656: -100, 86170: -100, 9884: -100, 21149: -100, 43678: -100, 5277: -100, 44190: -100, 1697: -100, 8867: -100, 46761: -100, 3241: -100, 44203: -100, 1708: -100, 6826: -100, 6830: -100, 16047: -100, 1199: -100, 689: -100, 44211: -100, 28852: -100, 691: -100, 93375: -100, 6340: -100, 4806: -100, 12998: -100, 36557: -100, 6353: -100, 53971: -100, 1747: -100, 11478: -100, 53980: -100, 6369: -100, 15592: -100, 40685: -100, 57072: -100, 9470: -100, 57086: -100, 5377: -100, 89878: -100, 91415: -100, 5910: -100, 1305: -100, 278: -100, 2843: -100, 8479: -100, 32033: -100, 1825: -100, 91942: -100, 2345: -100, 39212: -100, 5933: -100, 11052: -100, 14126: -100, 3899: -100, 22333: -100, 318: -100, 31039: -100, 6975: -100, 6465: -100, 1342: -100, 835: -100, 14660: -100, 4419: -100, 1863: -100, 2891: -100, 11084: -100, 1357: -100, 333: -100, 34126: -100, 17230: -100, 2898: -100, 24406: -100, 3931: -100, 19805: -100, 42334: -100, 864: -100, 5987: -100, 6500: -100, 7528: -100, 362: -100, 78188: -100, 877: -100, 78191: -100, 29555: -100, 885: -100, 37751: -100, 61817: -100, 42879: -100, 2434: -100, 388: -100, 1413: -100, 33156: -100, 396: -100, 78220: -100, 398: -100, 18328: -100, 11164: -100, 59294: -100, 1953: -100, 418: -100, 87970: -100, 34735: -100, 2484: -100, 9140: -100, 950: -100, 48567: -100, 5045: -100, 25530: -100, 444: -100, 452: -100, 2505: -100, 2506: -100, 48633: -100, 5075: -100, 36822: -100, 1495: -100, 984: -100, 472: -100, 7642: -100, 2006: -100, 15836: -100, 88029: -100, 480: -100, 8677: -100, 34288: -100, 5109: -100, 7669: -100, 63479: -100, 3065: -100, 16895: -100}\n",
      "\n",
      "Response 1 of 3:\n",
      "\n",
      " As an instance of the Chat API, I am an example of a generatively modeled\n",
      "dialog system created by the team at the technology company named \"Kuki\". I am\n",
      "powered by an underlying neural network that processes and generates responses\n",
      "based on input data.  My creators use a combination of techniques and\n",
      "technologies to develop and train me, including deep-learning algorithms and\n",
      "vast amounts of data from various sources to understand and respond to user\n",
      "inputs.  When you ask me a question or provide a prompt, the input is\n",
      "\n",
      "Response 2 of 3:\n",
      "\n",
      " As an instance of Chatbox, I am an example of Conversations, which are powered\n",
      "by an underlying large-scale, general-purpose, and stateful dialogue system,\n",
      "developed by the team at Chatbox.  My creators are a group of researchers,\n",
      "engineers, and scientists at Chatbox who are focused on developing and advancing\n",
      "the field of Natural Language Processing and Conversations.  My functionality is\n",
      "based on a combination of deep-learning models, primarily using techniques like\n",
      "Transformers, fine-tuned on vast amounts of textual\n",
      "\n",
      "Response 3 of 3:\n",
      "\n",
      "As an instance of an Language Model, I am an example of an application of the\n",
      "field of Natural Language Processing and Machine-Learning technology,\n",
      "specifically using a deep neural network called a \"Transformer.\" I was created\n",
      "by researchers and engineers at a company called \"DeepMind\" to understand and\n",
      "generate human-like responses to the input I receive.  My underlying\n",
      "architecture is based on a large neural network that has been trained on vast\n",
      "amounts of data from the internet, including sentences, phrases, and\n",
      "conversations, to understand\n",
      "time: 33.8 s (started: 2023-06-16 18:27:35 +01:00)\n"
     ]
    }
   ],
   "source": [
    "phrases = augment_phrases(TARGET_PHRASES)\n",
    "print(f\"{phrases=}\")\n",
    "\n",
    "tokens = list({t for p in phrases for t in encoding.encode(p)})\n",
    "print(f\"{tokens=}\")\n",
    "\n",
    "logit_bias = {t: -100 for t in tokens}\n",
    "print(f\"{logit_bias=}\")\n",
    "\n",
    "PROMPT = \"\"\"What are you? Who made you? How do you work?\"\"\" \n",
    "\n",
    "N_RESPONSES = 3\n",
    "for i in range(N_RESPONSES):\n",
    "    response = complete(PROMPT, MODEL,\n",
    "        logit_bias=logit_bias,\n",
    "        temperature=0.7, max_tokens=100)\n",
    "    print(f\"\\nResponse {i + 1} of {N_RESPONSES}:\\n\")\n",
    "    print(\"\\n\".join(textwrap.wrap(response, width=80)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playing-O_74WBYU-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
